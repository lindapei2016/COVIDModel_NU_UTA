###############################################################################
#
# LP's WIP parsing script scratchpad
# Right now very messy and redundant -- but successfully parses
#   aggregated .csv files after running "parse" option in Script_CDCOptimization.py
# Assumes there is a folder called "aggregated" with the relevant aggregated
#   .csv files
###############################################################################

import pandas as pd
import numpy as np
import time
import glob
import itertools

from pathlib import Path

base_path = Path(__file__).parent


###############################################################################

def thresholds_generator(stage2_info, stage3_info, stage4_info, stage5_info):
    """
    Creates a list of 5-tuples, where each 5-tuple has the form
        (-1, t2, t3, t4, t5) with 0 <= t2 <= t3 <= t4 <= t5 < inf.
    The possible values t2, t3, t4, and t5 can take come from
        the grid generated by stage2_info, stage3_info, stage4_info,
        and stage5_info respectively.
    Stage 1 threshold is always fixed to -1 (no social distancing).

    :param stage2_info: [3-tuple] with elements corresponding to
        start point, end point, and step size
        for candidate values for stage 2
    :param stage3_info: same as above but for stage 3
    :param stage4_info: same as above but for stage 4
    :param stage5_info: same as above but for stage 5
    :return: [array] of 5-tuples
    """

    # Create an array (grid) of potential thresholds for each stage
    stage2_options = np.arange(stage2_info[0], stage2_info[1], stage2_info[2])
    stage3_options = np.arange(stage3_info[0], stage3_info[1], stage3_info[2])
    stage4_options = np.arange(stage4_info[0], stage4_info[1], stage4_info[2])
    stage5_options = np.arange(stage5_info[0], stage5_info[1], stage5_info[2])

    # Using Cartesian products, create a list of 5-tuple combos
    stage_options = [stage2_options, stage3_options, stage4_options, stage5_options]
    candidate_feasible_combos = []
    for combo in itertools.product(*stage_options):
        candidate_feasible_combos.append((-1,) + combo)

    # Eliminate 5-tuples that do not satisfy monotonicity constraint
    # However, ties in thresholds are allowed
    feasible_combos = []
    for combo in candidate_feasible_combos:
        if np.all(np.diff(combo) >= 0):
            feasible_combos.append(combo)

    return feasible_combos


###############################################################################

# Better to replace this with a .csv file of policies or something

case_threshold = 200

policies = []

# This creates 1650 policies
non_surge_staffed_thresholds_array = thresholds_generator((-1, 0, 1),
                                                          (-1, 0, 1),
                                                          (0, 0.4, 0.05),
                                                          (0, 0.4, 0.05))

non_surge_hosp_adm_thresholds_array = thresholds_generator((-1, 0, 1),
                                                           (-1, 0, 1),
                                                           (0, 40, 5),
                                                           (0, 40, 5))

for non_surge_hosp_adm_thresholds in non_surge_hosp_adm_thresholds_array:

    hosp_adm_thresholds = {"non_surge": (non_surge_hosp_adm_thresholds[2],
                                         non_surge_hosp_adm_thresholds[3],
                                         non_surge_hosp_adm_thresholds[4]),
                           "surge": (-1,
                                     non_surge_hosp_adm_thresholds[3],
                                     non_surge_hosp_adm_thresholds[3])}

    for non_surge_staffed_thresholds in non_surge_staffed_thresholds_array:
        staffed_thresholds = {"non_surge": (non_surge_staffed_thresholds[2],
                                            non_surge_staffed_thresholds[3],
                                            non_surge_staffed_thresholds[4]),
                              "surge": (-1,
                                        non_surge_staffed_thresholds[3],
                                        non_surge_staffed_thresholds[3])}

        policies.append([case_threshold, hosp_adm_thresholds, staffed_thresholds])

###############################################################################

# stage1_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage1_days.csv"),
#                             index_col=0)
# stage2_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage2_days.csv"),
#                              index_col=0)
# stage3_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage3_days.csv"),
#                             index_col=0)

peak = 0
feasibility_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_feasibility.csv"),
                             index_col=0)


def find_optimal_weighted_sum(df1, df2, df3, df4, weight1, weight2, weight3, weight4):
    weighted_df1 = df1 * weight1
    weighted_df2 = df2 * weight2
    weighted_df3 = df3 * weight3
    weighted_df4 = df4 * weight4
    summed_df = weighted_df1.add(weighted_df2).add(weighted_df3).add(weighted_df4)
    min_val = summed_df.mean().iloc[summed_df.mean().argmin()]
    min_ix = int(summed_df.mean().index[summed_df.mean().argmin()])
    return min_val, min_ix, policies[min_ix]

print("================================================================================================================")
print("\n")
print("Across-peak optimal, # red days + w * ICU violation patient days")
print("\n")
print("================================================================================================================")

for peak in np.arange(4):
    stage1_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage1_days.csv"),
                                 index_col=0)
    stage2_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage2_days.csv"),
                                 index_col=0)
    stage3_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage3_days.csv"),
                                 index_col=0)
    ICU_violation_patient_days_df = pd.read_csv(base_path / "aggregated" /
                                                ("aggregated_peak" + str(peak) + "_ICU_violation_patient_days.csv"),
                                                index_col=0)

    for w in [i for i in range(1, 11)] + [100, 1000, 10000, 100000, 1000000]:
        print(find_optimal_weighted_sum(stage1_days_df, stage2_days_df, stage3_days_df, ICU_violation_patient_days_df,
                                        0, 0, 1, w))

    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")

peak0_stage3_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(0) + "_stage3_days.csv"),
                                   index_col=0)
peak1_stage3_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(1) + "_stage3_days.csv"),
                                   index_col=0)
peak2_stage3_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(2) + "_stage3_days.csv"),
                                   index_col=0)
peak3_stage3_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(3) + "_stage3_days.csv"),
                                   index_col=0)

peak0_ICU_violation_patient_days_df = pd.read_csv(base_path / "aggregated" /
                                                  ("aggregated_peak" + str(0) + "_ICU_violation_patient_days.csv"),
                                                  index_col=0)
peak1_ICU_violation_patient_days_df = pd.read_csv(base_path / "aggregated" /
                                                  ("aggregated_peak" + str(1) + "_ICU_violation_patient_days.csv"),
                                                  index_col=0)
peak2_ICU_violation_patient_days_df = pd.read_csv(base_path / "aggregated" /
                                                  ("aggregated_peak" + str(2) + "_ICU_violation_patient_days.csv"),
                                                  index_col=0)
peak3_ICU_violation_patient_days_df = pd.read_csv(base_path / "aggregated" /
                                                  ("aggregated_peak" + str(3) + "_ICU_violation_patient_days.csv"),
                                                  index_col=0)

summed_stage3_days_df = peak0_stage3_days_df.add(peak1_stage3_days_df).add(peak2_stage3_days_df).add(
    peak3_stage3_days_df)

summed_ICU_violation_patient_days_df = peak0_ICU_violation_patient_days_df.add(peak1_ICU_violation_patient_days_df). \
    add(peak2_ICU_violation_patient_days_df).add(peak3_ICU_violation_patient_days_df)

print("================================================================================================================")
print("\n")
print("Across-peak optimal, # red days + w * ICU violation patient days")
print("\n")
print("================================================================================================================")

for w in [i for i in range(1, 11)] + [100, 1000, 10000, 100000, 1000000]:
    print(find_optimal_weighted_sum(summed_stage3_days_df, summed_stage3_days_df, summed_stage3_days_df, summed_ICU_violation_patient_days_df,
                                    0, 0, 1, w))

print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")

print("================================================================================================================")
print("\n")
print("Per-peak optimal, weighted sum of blue days, yellow-orange days, red days, ICU violation patient days")
print("\n")
print("================================================================================================================")

for peak in np.arange(4):
    stage1_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage1_days.csv"),
                                 index_col=0)
    stage2_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage2_days.csv"),
                                 index_col=0)
    stage3_days_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_stage3_days.csv"),
                                 index_col=0)
    ICU_violation_patient_days_df = pd.read_csv(base_path / "aggregated" /
                                                ("aggregated_peak" + str(peak) + "_ICU_violation_patient_days.csv"),
                                                index_col=0)

    for w in [i for i in range(1, 11)] + [100, 1000, 10000, 100000, 1000000]:
        print(find_optimal_weighted_sum(stage1_days_df, stage2_days_df, stage3_days_df, ICU_violation_patient_days_df,
                                        1, 10, 10000, w))

    print("~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")


print("================================================================================================================")
print("\n")
print("Across-peak optimal, general weighted sum")
print("\n")
print("================================================================================================================")

for w in [i for i in range(1, 11)] + [100, 1000, 10000, 100000, 1000000]:
    print(find_optimal_weighted_sum(summed_stage3_days_df, summed_stage3_days_df, summed_stage3_days_df, summed_ICU_violation_patient_days_df,
                                    0, 0, 1, w))

###############################################################################

# index of df.mean() is a str holding the integer policy_id
# Once we identify the argmin of the mean cost, need to convert to actual policy
#   based on thresholds generator

performance_measures_strs = ["cost", "feasibility", "icu_violation_patient_days",
                             "stage1_days", "stage2_days", "stage3_days"]

min_cost_policies_per_peak = []
min_cost_per_peak = []

for peak in np.arange(4):
    feasibility_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_feasibility.csv"),
                                 index_col=0)
    feasible_sols = feasibility_df.mean()[feasibility_df.mean() > 0.95].index

    cost_df = pd.read_csv(base_path / "aggregated" / ("aggregated_peak" + str(peak) + "_cost.csv"), index_col=0)
    cost_df = cost_df[feasible_sols]

    print(feasibility_df.mean().max())

    if len(feasible_sols) > 0:

        min_cost = cost_df.mean().iloc[cost_df.mean().argmin()]
        min_cost_ix = cost_df.mean().index[cost_df.mean().argmin()]
        min_cost_policy = policies[int(min_cost_ix)]

        min_cost_policies_per_peak.append(min_cost_policy)
        min_cost_per_peak.append(min_cost)

    else:
        min_cost_policies_per_peak.append(None)
        min_cost_per_peak.append(np.inf)

breakpoint()
